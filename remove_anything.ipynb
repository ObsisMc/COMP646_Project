{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rz60/.conda/envs/COMP646/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/rz60/codes/COMP646/COMP646_Project/remove_anything/segment_anything/segment_anything/modeling/tiny_vit_sam.py:657: UserWarning: Overwriting tiny_vit_5m_224 in registry with segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/rz60/codes/COMP646/COMP646_Project/remove_anything/segment_anything/segment_anything/modeling/tiny_vit_sam.py:657: UserWarning: Overwriting tiny_vit_11m_224 in registry with segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/rz60/codes/COMP646/COMP646_Project/remove_anything/segment_anything/segment_anything/modeling/tiny_vit_sam.py:657: UserWarning: Overwriting tiny_vit_21m_224 in registry with segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/rz60/codes/COMP646/COMP646_Project/remove_anything/segment_anything/segment_anything/modeling/tiny_vit_sam.py:657: UserWarning: Overwriting tiny_vit_21m_384 in registry with segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/rz60/codes/COMP646/COMP646_Project/remove_anything/segment_anything/segment_anything/modeling/tiny_vit_sam.py:657: UserWarning: Overwriting tiny_vit_21m_512 in registry with segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "2024-04-17 20:59:06.682252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 20:59:08.277571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectron v2 is not installed\n"
     ]
    }
   ],
   "source": [
    "from remove_anything.remove_anything_function import remove_anything, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (534, 800)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "input_img = \"/home/sl237/COMP646_Project/remove_anything/remove-anything/dog.jpg\"\n",
    "img = cv2.imread(input_img)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "point_coords = [200, 450]  \n",
    "point_labels = [1]         \n",
    "dilate_kernel_size = 15\n",
    "sam_model_type = \"vit_h\"\n",
    "sam_ckpt = \"./remove_anything/pretrained_models/sam_vit_h_4b8939.pth\"\n",
    "lama_config = \"./remove_anything/lama/configs/prediction/default.yaml\"\n",
    "lama_ckpt = \"./remove_anything/pretrained_models/big-lama\"\n",
    "masks = test_mask(img, point_coords, point_labels,\n",
    "                sam_model_type, sam_ckpt)\n",
    "print(len(masks), masks[0].shape)\n",
    "masks = [masks[1]]\n",
    "mask_centers, res_inpaint_list  = remove_anything(img, dilate_kernel_size,\n",
    "                    lama_config, lama_ckpt, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, (534, 800))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(masks), masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(207, 379), (215, 375), (215, 266)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DOG\n",
    "input_img = \"./remove-anything/dog.jpg\"\n",
    "coords_type = \"key_in\"\n",
    "point_coords = [200, 450]\n",
    "point_labels = [1]         \n",
    "dilate_kernel_size = 15\n",
    "output_dir = \"./results\"\n",
    "sam_model_type = \"vit_h\"\n",
    "sam_ckpt = \"./remove_anything/pretrained_models/sam_vit_h_4b8939.pth\"\n",
    "lama_config = \"./remove_anything/lama/configs/prediction/default.yaml\"\n",
    "lama_ckpt = \"./remove_anything/pretrained_models/big-lama\"\n",
    "\n",
    "masks = remove_anything(input_img, coords_type, point_coords, point_labels,\n",
    "                dilate_kernel_size, output_dir, sam_model_type, sam_ckpt,\n",
    "                lama_config, lama_ckpt)\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(633, 1123), (652, 1050), (653, 1050)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAT\n",
    "input_img = \"./remove-anything/cat.jpg\"\n",
    "coords_type = \"key_in\"\n",
    "point_coords = [560, 1100]  \n",
    "point_labels = [1]         \n",
    "dilate_kernel_size = 15\n",
    "output_dir = \"./results\"\n",
    "sam_model_type = \"vit_h\"\n",
    "sam_ckpt = \"./pretrained_models/sam_vit_h_4b8939.pth\"\n",
    "lama_config = \"./lama/configs/prediction/default.yaml\"\n",
    "lama_ckpt = \"./pretrained_models/big-lama\"\n",
    "\n",
    "masks = remove_anything(input_img, coords_type, point_coords, point_labels,\n",
    "                dilate_kernel_size, output_dir, sam_model_type, sam_ckpt,\n",
    "                lama_config, lama_ckpt)\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(308, 547), (308, 560), (319, 567)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOAT\n",
    "input_img = \"./remove-anything/boat.jpg\"\n",
    "coords_type = \"key_in\"\n",
    "point_coords = [300, 550]  \n",
    "point_labels = [1]         \n",
    "dilate_kernel_size = 15\n",
    "output_dir = \"./results\"\n",
    "sam_model_type = \"vit_h\"\n",
    "sam_ckpt = \"./pretrained_models/sam_vit_h_4b8939.pth\"\n",
    "lama_config = \"./lama/configs/prediction/default.yaml\"\n",
    "lama_ckpt = \"./pretrained_models/big-lama\"\n",
    "\n",
    "masks = remove_anything(input_img, coords_type, point_coords, point_labels,\n",
    "                dilate_kernel_size, output_dir, sam_model_type, sam_ckpt,\n",
    "                lama_config, lama_ckpt)\n",
    "masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP646",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
